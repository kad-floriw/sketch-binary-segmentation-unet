{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import shutil\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import keras.callbacks\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "data_dir = '/tmp/data'\n",
    "train_dir = '/tmp/traindata'\n",
    "validation_dir = '/tmp/validationdata'\n",
    "images_dir, masks_dir = 'images', 'masks'\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  shutil.rmtree(data_dir)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "zip_ref = zipfile.ZipFile('/content/gdrive/My Drive/data.zip', 'r')\n",
    "zip_ref.extractall(data_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  shutil.rmtree(train_dir)\n",
    "except:\n",
    "  pass\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "try:\n",
    "  shutil.rmtree(validation_dir)\n",
    "except:\n",
    "  pass\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "split = .95\n",
    "file_names = os.listdir(os.path.join(data_dir, masks_dir))\n",
    "split_index = int(split * len(file_names))\n",
    "\n",
    "try:\n",
    "  shutil.rmtree(os.path.join(train_dir, images_dir))\n",
    "except:\n",
    "  pass\n",
    "os.mkdir(os.path.join(train_dir, images_dir))\n",
    "\n",
    "try:\n",
    "  shutil.rmtree(os.path.join(train_dir, masks_dir))\n",
    "except:\n",
    "  pass\n",
    "os.mkdir(os.path.join(train_dir, masks_dir))\n",
    "\n",
    "train_names = file_names[:split_index]\n",
    "np.random.shuffle(train_names)\n",
    "\n",
    "for file_name in train_names:\n",
    "  shutil.copyfile(os.path.join(data_dir, images_dir, file_name),\n",
    "                  os.path.join(train_dir, images_dir, file_name))\n",
    "  shutil.copyfile(os.path.join(data_dir, masks_dir, file_name),\n",
    "                  os.path.join(train_dir, masks_dir, file_name))\n",
    "\n",
    "try:\n",
    "  shutil.rmtree(os.path.join(validation_dir, images_dir))\n",
    "except:\n",
    "  pass\n",
    "\n",
    "os.mkdir(os.path.join(validation_dir, images_dir))\n",
    "\n",
    "try:\n",
    "  shutil.rmtree(os.path.join(validation_dir, masks_dir))\n",
    "except:\n",
    "  pass\n",
    "\n",
    "os.mkdir(os.path.join(validation_dir, masks_dir))\n",
    "\n",
    "validation_names = file_names[split_index:]\n",
    "np.random.shuffle(validation_names)\n",
    "for file_name in validation_names:\n",
    "  shutil.copyfile(os.path.join(data_dir, images_dir, file_name),\n",
    "                  os.path.join(validation_dir, images_dir, file_name))\n",
    "  shutil.copyfile(os.path.join(data_dir, masks_dir, file_name),\n",
    "                  os.path.join(validation_dir, masks_dir, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (1280, 768)\n",
    "\n",
    "def data_generator(data_path, seed=1): \n",
    "  image_data_generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "  image_generator = image_data_generator.flow_from_directory(\n",
    "        data_path, classes=[images_dir], class_mode=None,\n",
    "        color_mode='grayscale', target_size=image_shape, batch_size=1,\n",
    "        seed=seed)\n",
    "  \n",
    "  mask_generator = image_data_generator.flow_from_directory(\n",
    "      data_path, classes=[masks_dir], class_mode=None,\n",
    "      color_mode='grayscale', target_size=image_shape, batch_size=1,\n",
    "      seed=seed)\n",
    "  \n",
    "  for img, mask in zip(image_generator, mask_generator):\n",
    "    img /= 255\n",
    "    mask /= 255\n",
    "\n",
    "    yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_instance = data_generator(train_dir)\n",
    "\n",
    "for _ in range(1):\n",
    "  image, mask = next(train_generator_instance)\n",
    "  plt.imshow(np.hstack((np.squeeze(image[0] * 255).astype(np.uint8),\n",
    "                        np.invert(np.squeeze(mask[0] * 255).astype(np.uint8)))),\n",
    "             cmap='gray')\n",
    "  plt.show()\n",
    "\n",
    "validation_generator_instance = data_generator(validation_dir)\n",
    "\n",
    "for _ in range(1):\n",
    "  image, mask = next(validation_generator_instance)\n",
    "  plt.imshow(np.hstack((np.squeeze(image[0] * 255).astype(np.uint8),\n",
    "                        np.invert(np.squeeze(mask[0] * 255).astype(np.uint8)))),\n",
    "             cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet():\n",
    "    inputs = keras.layers.Input((image_shape[0], image_shape[1], 1))\n",
    "\n",
    "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = keras.layers.Dropout(0.5)(conv4)\n",
    "    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = keras.layers.Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = keras.layers.Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(keras.layers.UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = keras.layers.concatenate([drop4, up6], axis=3)\n",
    "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = keras.layers.Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(keras.layers.UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = keras.layers.concatenate([conv3, up7], axis = 3)\n",
    "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = keras.layers.Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(keras.layers.UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = keras.layers.concatenate([conv2, up8], axis = 3)\n",
    "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = keras.layers.Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(keras.layers.UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = keras.layers.concatenate([conv1, up9], axis=3)\n",
    "\n",
    "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = keras.layers.Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = keras.layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = keras.models.Model(input=inputs, output=conv10)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_checkpoint_dir = '/content/gdrive/My Drive/unet_snapshot/weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=20,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(weights_checkpoint_dir,\n",
    "                                                   monitor='val_loss',\n",
    "                                                   save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator_instance,\n",
    "                              steps_per_epoch=3536,\n",
    "                              epochs=250,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator_instance,\n",
    "                              validation_steps=187,\n",
    "                              shuffle=True,\n",
    "                              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = next(validation_generator_instance)\n",
    "\n",
    "output = model.predict([image], verbose=1)\n",
    "result = np.hstack((np.invert(np.squeeze(mask * 255).astype(np.uint8)),\n",
    "                    np.squeeze(image * 255).astype(np.uint8),\n",
    "                    np.invert(np.squeeze(output * 255).astype(np.uint8))))\n",
    "\n",
    "plt.imshow(result, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('/content/gdrive/My Drive/result.png', result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "unet_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
